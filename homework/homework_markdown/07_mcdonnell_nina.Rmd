---
title: "BIOL 607 Homework 7"
author: "Nina McDonnell"
date: "Nov 2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning= FALSE, message = FALSE)

#libraries 
library(dplyr)
library(ggplot2)
library(tidyr)
library(rsample)
library(purrr)
library(modelr)
library(AICcmodavg)
library(palmerpenguins)
library(RColorBrewer)
library(ggdist)
library(brms)
library(reticulate)

set.seed(802)

MorphRawData <-read.csv(file ="https://raw.githubusercontent.com/ninamcdonnell/ribbit/master/2019_2020_combined_metamorph_raw_data.csv") #includes NA values
str(MorphRawData)

metamorph <- MorphRawData%>%
  mutate(treatment=as.factor(treatment))%>%
  mutate(mesocosm = as.factor(mesocosm))%>%
  mutate(year=as.factor(year)) %>% 
  mutate(body_condition=mass/svl)%>%
  rename(day=metamorph_day) %>% 
  rename(mass=mass)%>%
  rename(svl=svl)%>%
  mutate(BodyCondition=mass/svl)

```

### Question 1: Create models with different polys

Let’s first look at the data. Plot it, along with a polynomial fit (remember, formula = y ~ poly(x,2) for a quadratic). Then, compare the r2 value of a linear versus fifth order fit. What do you see?

```{r 1}
#read in data
progesterone_data <- read.csv("homework/homework_data/chap17q07ProgesteroneExercise.csv")

#what's here
str(progesterone_data)

#plot linear and fifth-order polynomial fits
ggplot(progesterone_data, aes(x=ventilation, y=progesterone))+
  geom_point()+
  stat_smooth(method = "lm",se=FALSE)+
  stat_smooth(method="lm", formula=y ~ poly(x, 5), se=FALSE, color="red")

#linear fit model
progesterone_linear <- lm(progesterone~ventilation, data=progesterone_data)
#r2
summary(progesterone_linear)$r.squared

#5th order fit model
progesterone_5order <- lm(progesterone ~ poly(ventilation,5), data = progesterone_data)
#r2
summary(progesterone_5order)$r.squared

```
**The r-squared value is greater for the 5th order fit (`r summary(progesterone_5order)$r.squared`) than then linear fit (`r summary(progesterone_linear)$r.squared`). This means that the 5th order fit explains more of the observed variation than the linear fit.**

### Question 2: Fit each model with 5-fold CV

Does that result hold up, or is it due to overfitting? Let’s evaluate by comparing 5-fold CV scores using RMSE. Let’s do this efficiently, though!

A. Get things ready! Make a 5-fold cross validation tibble using 
#rsample::vfold_cv() and then combine each possible fold with the 
#polynomials 1:5 using tidyr::crossing()

```{r 2a}
#make cv tibble, folds=5
progesterone_5order_five_fold <- vfold_cv(progesterone_data, v=5)
progesterone_5order_five_fold

#combine each fold with polynomials 1:5
cv_df <- crossing(progesterone_5order_five_fold, poly=1:5)
cv_df
#str(cv_df)

```

B. Now you have splits and a column of coefficients. Use purr::map2() to make a list column of fit models, where you use the splits and data and the polynomials for you poly() call in the model.

```{r 2b}
model_df <- cv_df %>% #make data frame
  mutate(mods= map2(.x=splits, #for each split
                   .y=poly, #use poly to fit a lm
                   ~lm(progesterone ~ poly(ventilation,.y),
                          data= analysis(.x)))) 
model_df
```

C. Great! Now, calculate the rmse for each fold/polynomial combination as we did in lab.

```{r 2c}

#add rmse to data frame
model_df <- model_df %>% 
  mutate(rmse = map2_dbl(splits, 
                         mods, #for each split and mod, calculate...
                         ~rmse(model = .y, #rmse of model .y from data .x
                               data=assessment(.x))))

# we looked at this during office hours and could not figure out why the code wasnt working
```

D. Implications - ok, given that the 5-fold score is the average RMSE across all folds for a given polynomial, show in both a table and figure the relationship between polynomial and out-of-sample RMSE. What does this tell you?

```{r 2d}
#coded out what this would be if 2c was working:

# calculate mean rmse for each polymomial
rmse_table<- model_df %>% 
  select(poly, rmse)
  group_by(poly) %>% 
  summarize(mean_rmse=mean(rmse),
            sd_rmse=sd(rmse)) %>% 
    #make a table
    as.table() 

#plot rmse by model
rmse_plot <- model_df %>% 
  ggplot(aes(x=poly, y=rmse))+
  geom_boxplot()

```

**I am guessing that this would have shown greater rmse for overfit models because they account for more of the in-sample variation at the cost of better out of sample prediction (they are poor reflections of larger scale patterns).**

### Question 3: Compare models and see how they differ from AIC

That was all well and good, but, how to these results compare to doing this analysis with AIC using the {AICcmodavg} package? Note, you can use dplyr and purrr to not have to fit each model manually.

```{r 3}
#start with poly orders
poly_list <- c(1,2,3,4,5)

#with each poly, fit a glm
poly_mods <- poly_list %>% 
  map(~glm(progesterone ~ poly(ventilation,.), data=progesterone_data, family = gaussian(link="identity")))

#set up models for AIC table
mod_list <- poly_mods
name_vec <- c("linear", "squared", "cubed", "4-order","5-order")

#Use AIC table for model comparison- lower AIC= better
aictab(cand.set = mod_list, modnames = name_vec) #the third-order fit is ranked best

```

**The third-order fit has the lowest AIC. This model represents the observed variability better than the linear model, but is not as heavily penalized for number of parameters as the higher-order fits.**

### Question 5: Grid sample with Bayes

Last week, we did grid sampling with Likelihood. This week, let’s do it with Bayes!

A. Let’s start with the Palmer Penguins data. Let’s look at just the Gentoo. Why don’t you plot the distribution of the average flipper length of females. We’ll use this data for the exercise. Remember to remove NAs - it will make the rest of the exercise easier. 1 EC for each thing you do to snaz the plot up.

``` {r 5a}

#load penguin data
data(penguins)

#filter to gentoo females, remove NAs
gentoo_f <- penguins %>% 
  filter(species == "Gentoo", sex== "female") %>% 
  filter(flipper_length_mm>0, na.rm=TRUE)

#plot distribution of flipper length, use stat_halfeye to visualize mean and intervals
ggplot(gentoo_f, aes(x=flipper_length_mm, fill=flipper_length_mm))+
  stat_halfeye(fill="lightblue1", slab_colour="black", slab_size=.5)+
  labs(x="Flipper length (mm)", y="Frequency", title="Distribution of flipper lengths for female Gentoo penguins")+
  theme_bw()

```

B. OK, this is pretty normal, with a mean of 212.71 and sd of 3.9. Make a grid to search a number of values around that mean and SD, just as you did for likelihood. Let’s say 100 values of each parameter.

``` {r 5b}

#cross 100 valyes of mean with 100 values of sd
lik_df <- crossing(mean = seq(212, 220, length.out = 100),
                           sd= seq(1, 5, length.out = 100))

```

C. Write a function that will give you the numerator for any combination of m and s! This is just the same as writing a function for likelihood, but including an additional multiplier of p(H), when putting in the likelihood. Let’s assume a prior for m of dnorm(210, 50) and for s of dunif(1,10) - so, pretty weak!
So, we want p(m, s|flipper length)*p(m)*p(s).

BUT - small problem. These numbers get so vanishingly small, we can no longer do calculations with them. So, for any probability density you use, add log=TRUE and take a sum instead of products or multiplication, as

log(p(D|H)p(H))=log(p(D|H))+log(p(H))


``` {r 5c}
#a function to get the numerator given m and s
bayes_fn <- function(m, s){
  posterior <- sum(dnorm(gentoo_f$flipper_length_mm, m, s, log="TRUE"))+
    dnorm(m,210, 50, log="TRUE")+dunif(s,1,10, log="TRUE")
}

#test function
bayes_fn(m=200, s=30)
```

D. Great! Now use this function with your sample grid to get the numerator of the posterior, and then standardize with the p(D) - the sum of all numerators - to get a full posterior. Note, as we’re working in logs, we just subtract log(p(D)) What is the modal estimate of each parameter? How do they compare to the standard frequentist estimate?

``` {r 5d}

```

### Question 6: Final Project Thinking

We’re at the half-way point in the course, and after the mid-term, it’s time to start thinking about your final project. So…. I want to know a bit about what you’re thinking of!

A. What is the dataset you are thinking of working with? Tell me a bit about what’s in it, and where it comes from.

**I am thinking of exploring a leopard frog morphometric dataset I collected over the past two summers. I have data on mass, body length, and time to metamorphosis (larval period) of indiviuals from 5 different community treatments (15 outdoor mesocosms, 3 replicates/treatment, total of 300 individuals). These data will be used to calculate body condition, and ultimately correlated with disease metrics, but disease diagnostics and immune sample processing will not be finished for a while. For now, my goal is to build a model to test for treatment differences in mass, larval period, and body condition between prescribed communities, which can later be modified to incorporate disease variables. Tadpole density was held constant while manipulating community, but disease was not examined separately from community structure, so differences represent total effects of interspecies host interactions plus host-mediated disease effects**

B. What question do you want to ask of that data set?

**1. Do mass, body condition, or larval period differ significantly with study year or treatment?**
**2. Does the effect of treatment differ with study year (is there an interaction)?**
**3. Do mass, body condition, and larval period exhibit collinearity? For later: How do these qualities vary in their strength of association with disease?**

EC C. Wanna make a quick visualization of some aspect of the data that might be provocative and interesting?

```{python}

fig <- plot_ly(metamorph, x = ~day, y = ~body_condition, z = ~mass,color = ~year, colors="Dark2") %>% 
  add_markers() %>% 
  layout(scene = list(xaxis = list(title = "Days to metamorphosis"),
                                   yaxis = list(title = "Body condition (g/mm)"),
                                   zaxis = list(title = "Mass, g")))
```



## <span style="color: red;">*Extra credit:* submitted via GitHub.</span>
### <span style="color: red;">Repository: https://github.com/ninamcdonnell/biol607_mcdonnell/tree/master/homework/homework_markdown
</span>

